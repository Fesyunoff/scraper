# Scraper

Нам необходимо написать сервис мониторинг доступности определенного набора сервисов.

Список сервисов находится в файле sites.txt. Каждую минуту мы должны проверять доступность и время доступа к сервису. Также у нас есть огромное количество пользователей которые хотя знать время доступа к сервису. Они могут запросить время доступа к случайному сервису, либо запросить сервис с максимальным временем доступа, либо запросить сервис с минимальным временем доступа. Также у нас есть администарторы, которые хотят отслеживать статистику запросов от пользователей по всем сервисам.

На данный момент реализовано:
```
- постоянный мониторинг с ежеминутным обновлением доступности сервисов
- при перезапуске список сервисов обновляется, если файл содержит записи,
  которых нет в хранилище.
- запросы вида (доступны только авторизованным пользователям):
              getAvailability?site=example.com   
              getResponceTime?limit=max
              getResponceTime?limit=min
- запрос статистики (доступно только администратору):
              getStatistics?hours=0&limit=0
    (прим. hours - время в часах за которое берется статистика (если равно '0' то статистика
    за последине сутки), 
    limit - количество сервисов, которые включаются в ответ, сервисы  отсортированы по 
    убыванию популярности (если равно '0' то отображаются первые 50 сервисов))
- авторизация через --header "X-User-Id: 1" (при запуске создается администаратор с id=1 и 
  и пользователи с id=[2,3,4])
```

## Example


Build Service:
<code>
go build -o ./bin/scraper ./cmd/scraper/
</code>

Start Service:
<code>
./bin/service
</code>

Test Service:
<code>
chmod +x ./test_script 
</code>


<code>
./test_script
</code>
